"""ì‚¬ìš©ì ì·¨í–¥ ê´€ë¦¬ ëª¨ë“ˆ â€” ğŸ‘ í”¼ë“œë°± ê¸°ë°˜ + ì¤‘ë³µ ë°©ì§€"""

from supabase import create_client
from datetime import datetime, timedelta
from typing import List, Optional


def get_supabase_client(url: str, key: str):
    """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    return create_client(url, key)


def save_article(client, article: dict, briefing_type: str = "daily"):
    """ì¶”ì²œëœ ì•„í‹°í´ì„ DBì— ì €ì¥"""
    data = {
        "title": article.get("title", ""),
        "url": article.get("url", ""),
        "source": article.get("source", ""),
        "axis_id": article.get("axis_id"),
        "axis_name": article.get("axis_name", ""),
        "why_new": article.get("why_new", ""),
        "new_concept_name": article.get("new_concept_name", ""),
        "new_concept_desc": article.get("new_concept_desc", ""),
        "why_read": article.get("why_read", ""),
        "read_time": article.get("read_time", ""),
        "briefing_type": briefing_type,
        "status": "sent",
    }
    result = client.table("articles").insert(data).execute()
    return result.data[0] if result.data else None


def save_news(client, news: dict):
    """ë‰´ìŠ¤ ì•„ì´í…œì„ DBì— ì €ì¥"""
    data = {
        "title": news.get("title", ""),
        "url": news.get("url", ""),
        "source": news.get("source", ""),
        "hashtag": news.get("hashtag", ""),
        "summary_line_1": news.get("summary_line_1", ""),
        "summary_line_2": news.get("summary_line_2", ""),
        "summary_line_3": news.get("summary_line_3", ""),
        "status": "sent",
    }
    result = client.table("news").insert(data).execute()
    return result.data[0] if result.data else None


def save_feedback(client, article_url: str, reaction: str, memo: str = ""):
    """ì´ëª¨ì§€ í”¼ë“œë°± ì €ì¥"""
    data = {
        "article_url": article_url,
        "reaction": reaction,
        "memo": memo,
    }
    # articles í…Œì´ë¸” ìƒíƒœ ì—…ë°ì´íŠ¸
    status_map = {"star": "starred", "bookmark": "archived", "thumbsdown": "skipped"}
    new_status = status_map.get(reaction, "sent")

    client.table("articles").update({"status": new_status}).eq("url", article_url).execute()
    client.table("feedback").insert(data).execute()


def get_recent_urls(client, days: int = 7) -> set:
    """ìµœê·¼ Nì¼ ë‚´ ì¶”ì²œëœ ì•„í‹°í´/ë‰´ìŠ¤ URL ëª©ë¡ (ì¤‘ë³µ ë°©ì§€ìš©)"""
    cutoff = (datetime.utcnow() - timedelta(days=days)).isoformat()

    recent_urls = set()

    articles = client.table("articles").select("url").gte("created_at", cutoff).execute()
    for a in (articles.data or []):
        if a.get("url"):
            recent_urls.add(a["url"])

    news = client.table("news").select("url").gte("created_at", cutoff).execute()
    for n in (news.data or []):
        if n.get("url"):
            recent_urls.add(n["url"])

    return recent_urls


def get_excluded_topics(client) -> List[str]:
    """ğŸ‘ í”¼ë“œë°±ì—ì„œ ì œì™¸í•  í† í”½ íŒ¨í„´ ì¶”ì¶œ"""
    result = client.table("feedback").select("*").eq("reaction", "thumbsdown").execute()

    if not result.data:
        return []

    # ğŸ‘ ë°›ì€ ì•„í‹°í´ì˜ axis, source íŒ¨í„´ ë¶„ì„
    skipped_axes = {}
    skipped_sources = {}

    for fb in result.data:
        url = fb.get("article_url", "")
        # í•´ë‹¹ ì•„í‹°í´ ì •ë³´ ì¡°íšŒ
        article = client.table("articles").select("*").eq("url", url).execute()
        if article.data:
            a = article.data[0]
            axis = a.get("axis_name", "")
            source = a.get("source", "")
            if axis:
                skipped_axes[axis] = skipped_axes.get(axis, 0) + 1
            if source:
                skipped_sources[source] = skipped_sources.get(source, 0) + 1

    # 3íšŒ ì´ìƒ ğŸ‘ ë°›ì€ í† í”½/ì†ŒìŠ¤ ì œì™¸
    excluded = []
    for topic, count in skipped_axes.items():
        if count >= 3:
            excluded.append(f"Axis: {topic}")
    for source, count in skipped_sources.items():
        if count >= 3:
            excluded.append(f"Source: {source}")

    return excluded


def get_weekly_stats(client) -> dict:
    """ì£¼ê°„ í†µê³„"""
    from datetime import datetime, timedelta
    week_ago = (datetime.utcnow() - timedelta(days=7)).isoformat()

    # ì´ë²ˆ ì£¼ ì¶”ì²œëœ ì•„í‹°í´
    articles = client.table("articles").select("*").gte("created_at", week_ago).execute()

    # ì´ë²ˆ ì£¼ í”¼ë“œë°±
    feedback = client.table("feedback").select("*").gte("created_at", week_ago).execute()

    total = len(articles.data) if articles.data else 0
    starred = len([a for a in (articles.data or []) if a.get("status") == "starred"])
    archived = len([a for a in (articles.data or []) if a.get("status") == "archived"])
    skipped = len([a for a in (articles.data or []) if a.get("status") == "skipped"])

    # Axisë³„ í†µê³„
    axis_counts = {}
    for a in (articles.data or []):
        axis = a.get("axis_name", "Unknown")
        axis_counts[axis] = axis_counts.get(axis, 0) + 1

    starred_articles = [a for a in (articles.data or []) if a.get("status") == "starred"]

    return {
        "total": total,
        "starred": starred,
        "archived": archived,
        "skipped": skipped,
        "axis_counts": axis_counts,
        "starred_articles": starred_articles,
    }
