"""Groq ê¸°ë°˜ 3-ì—ì´ì „íŠ¸ íë ˆì´ì…˜ ì‹œìŠ¤í…œ

Agent 1: Selector â€” 25ê°œ ì¤‘ ìµœì  ì•„í‹°í´ ì„ ë³„
Agent 2: Analyst â€” ì„ ë³„ëœ ì•„í‹°í´ì˜ 3-Point Card ì‘ì„±
Agent 3: Connector â€” ì•„í‹°í´ ê°„ ì—°ê²°ê³ ë¦¬ ë°œê²¬
"""

import json
import yaml
import os
from groq import Groq
from typing import List, Dict


ALBERT_CONTEXT = """
## WHO IS ALBERT
Albert(ì•Œë²—)ëŠ” AI ì‹œëŒ€ì— ì¸ê°„ì˜ ìƒê°í•˜ëŠ” í˜ì„ ê·¹ëŒ€í™”í•˜ëŠ” ì‚¶ì„ ì‹¤í—˜í•˜ê³ , ê·¸ ë°©ë²•ì„ íƒ€ì¸ì—ê²Œ ì „ë‹¬í•˜ë ¤ëŠ” Scholar-Practitionerì´ë‹¤.

## BACKGROUND
- ê²½í¬ëŒ€ êµ­ì œí•™ê³¼ (UCë²„í´ë¦¬ êµí™˜, ì°¨ì„ì¡¸ì—…) â†’ ì„œìš¸ëŒ€ ì™¸êµí•™ ì„ì‚¬ â†’ American University êµ­ì œê´€ê³„í•™ ë°•ì‚¬ìˆ˜ë£Œ
- ë””ë² ì´íŠ¸í¬ì˜¬ ì‹œë‹ˆì–´ê°•ì‚¬ 8ë…„: ë…¼ì¦ê³¼ ë¹„íŒì  ì‚¬ê³  êµìœ¡ ì „ë¬¸ê°€
- ê¸€ì“°ê¸° ì½”ì¹˜, ì„±ì¥ íŒŒíŠ¸ë„ˆ: Microflow ê¸€ì“°ê¸° í”„ë¡œê·¸ë¨ ìš´ì˜
- í˜„ì¬ ì´ì§ íƒìƒ‰ ì¤‘, 10ë…„ í›„ ëª©í‘œëŠ” Scholar-Practitioner (ê¸°ì—… ê°•ì˜, ëª…ìƒ ê¸°ë°˜ ìƒì‚°ì„± ì§€ë„, ê¸€ì“°ê¸°+í†µì°° í”„ë¡œê·¸ë¨)

## DAILY PRACTICE
- ë§¤ì¼ Hatha Yoga, ë‹¨ì „í˜¸í¡(í˜„ì¬ 24ì´ˆ-24ì´ˆ, ëª©í‘œ íƒœì‹ 2ë¶„-2ë¶„), ëª…ìƒ ìˆ˜í–‰
- ê¸°ê° í˜•ì„±ë¨, 1ë…„+ ìˆ˜í–‰ ì§€ì†
- ìš”ëª…ì°¨: ìš”ê°€Â·ëª…ìƒÂ·ì°¨Â·ê¸€ì“°ê¸°ë¥¼ ê²°í•©í•œ ê°œì¸ ë£¨í‹´

## CORE BELIEFS
- AIëŠ” ë‹¨ìˆœ ìƒì‚°ì„± ë„êµ¬ê°€ ì•„ë‹ˆë¼ "ì¸ì§€ í™•ì¥ ì¥ì¹˜"
- ê½‚íˆëŠ” ê²ƒì´ ì•„ë‹ˆë©´ ì§‘ì¤‘ ì–´ë ¤ì›€ â†’ ì˜ë¯¸ ì—°ê²° íŒ¨í„´ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ì‚¬ëŒ
- ì„±ê³µë³´ë‹¤ "ì˜ì‹ì  ì§„í™”"ê°€ ì‚¶ì˜ ì¤‘ì‹¬ì¶•
- ì˜í–¥ì„ ì¤€ ì¸ë¬¼: ì´ë‚˜ëª¨ë¦¬ ê°€ì¦ˆì˜¤, ì•¼ë§ˆêµ¬ì¹˜ ìŠˆ, ë‚˜ë°œ ë¼ë¹„ì¹¸íŠ¸, Chris Williamson, Dan Koe (ê³µí†µì : ê¹Šì€ ì‚¬ìœ ì™€ ì‹¤í–‰ì„ ì—°ê²°ì‹œí‚¨ ì‚¬ëŒë“¤)

## WHAT ALBERT NEEDS FROM THIS CURATION
- ë¹ ë¥´ê²Œ ë³€í™”í•˜ëŠ” íŠ¸ë Œë“œì˜ ì² í•™ì /ì‚¬ìƒì /íŒ¨ëŸ¬ë‹¤ì„ì  ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ê³  ì‹¶ë‹¤
- ìƒˆë¡œìš´ ê°œë…, í”„ë ˆì„ì›Œí¬, íŒ¨ëŸ¬ë‹¤ì„ì„ ì ‘í•˜ê³  ì‹¶ë‹¤
- ê°•ì˜ì™€ ì½”ì¹­ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì§€ì  ìì‚°ì„ ìŒ“ê³  ì‹¶ë‹¤
- ìì‹ ì˜ ìˆ˜í–‰(ìš”ê°€/í˜¸í¡/ëª…ìƒ)ì— ê³¼í•™ì  ê·¼ê±°ì™€ ì§€ì  í”„ë ˆì„ì„ ì—°ê²°í•˜ê³  ì‹¶ë‹¤
- "ì¼í•˜ëŠ” ì‚¬ëŒì˜ ì„±ì¥ì„ ë•ëŠ”" ì»¤ë¦¬ì–´ ë¯¸ì…˜ì— ì˜ê°ì„ ì¤„ ì½˜í…ì¸ ê°€ í•„ìš”í•˜ë‹¤

## TONE GUIDE
- Genericí•˜ê±°ë‚˜ ë»”í•œ ìš”ì•½ì€ ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ
- Albertì˜ êµ¬ì²´ì  ìƒí™©ê³¼ ì—°ê²°ëœ "So What"ì„ ì œì‹œí•  ê²ƒ
- ìƒˆë¡œìš´ ìš©ì–´ë‚˜ ê°œë…ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ì§šì–´ì¤„ ê²ƒ
- í•œêµ­ì–´ ìš”ì•½ì€ ìì—°ìŠ¤ëŸ½ê³  ë°€ë„ ë†’ê²Œ, ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ì œê±°
"""


ARTICLE_EXAMPLE = """
## GOOD EXAMPLE (3-Point Card)

Title: "The Case Against Cognitive Outsourcing"
Source: Noema Magazine

ğŸ†• ì™œ ìƒˆë¡œìš´ê°€
AIì—ê²Œ ì‚¬ê³ ë¥¼ ìœ„ì„í•˜ëŠ” ê²ƒì´ "ì¸ì§€ í™•ì¥"ì´ ì•„ë‹ˆë¼ "ì¸ì§€ ìœ„ì¶•"ì´ë¼ëŠ” ë°˜ë¡ ì´ ë³¸ê²© ë“±ì¥. Extended Mind ì´ë¡ ì— ëŒ€í•œ ì²´ê³„ì  ë°˜ë°•.

ğŸ’ ìƒˆë¡œìš´ ê°œë…
Cognitive Atrophy (ì¸ì§€ ìœ„ì¶•) â€” ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì¸ì§€ ëŠ¥ë ¥ì€ ê·¼ìœ¡ì²˜ëŸ¼ í‡´í™”í•œë‹¤ëŠ” í”„ë ˆì„ì›Œí¬. AI ì˜ì¡´ë„ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ ë©”íƒ€ì¸ì§€ ëŠ¥ë ¥ì´ ì•½í™”ëœë‹¤ëŠ” ì£¼ì¥.

ğŸ¯ ì™œ ì½ì–´ì•¼ í•˜ëŠ”ê°€
AIë¥¼ ì¸ì§€ í™•ì¥ ì¥ì¹˜ë¡œ ì“°ëŠ” Albertì˜ ì „ì œë¥¼ ì •ë©´ìœ¼ë¡œ ë„ì „í•˜ëŠ” ê¸€. ë°˜ë¡ ì„ ì•Œì•„ì•¼ ìê¸° ì…ì¥ì´ ë‹¨ë‹¨í•´ì§„ë‹¤. ì½”ì¹­/ê°•ì˜ì—ì„œ "AIë¥¼ ì–´ë–»ê²Œ ì¨ì•¼ í•˜ëŠ”ê°€" ë…¼ì˜ì˜ í•µì‹¬ ë ˆí¼ëŸ°ìŠ¤.

## BAD EXAMPLE (too generic, avoid this)
ğŸ†• ì™œ ìƒˆë¡œìš´ê°€: AIì™€ ì¸ì§€ì— ëŒ€í•œ ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí•©ë‹ˆë‹¤.
ğŸ’ ìƒˆë¡œìš´ ê°œë…: ì¸ì§€ ìœ„ì¶•ì´ë¼ëŠ” ê°œë…ì´ ì†Œê°œë©ë‹ˆë‹¤.
ğŸ¯ ì™œ ì½ì–´ì•¼ í•˜ëŠ”ê°€: AI ì‹œëŒ€ì— ì¤‘ìš”í•œ ì£¼ì œì…ë‹ˆë‹¤.
"""


def load_axes(config_path: str = None) -> List[Dict]:
    """Axes ì„¤ì • ë¡œë“œ"""
    if config_path is None:
        config_path = os.path.join(
            os.path.dirname(__file__), "..", "..", "config", "axes.yml"
        )
    with open(config_path, "r") as f:
        config = yaml.safe_load(f)
    return config.get("axes", [])


def init_model(api_key: str):
    """Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    return Groq(api_key=api_key)


def _call_groq(client, prompt: str) -> str:
    """Groq API í˜¸ì¶œ ê³µí†µ í•¨ìˆ˜"""
    response = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=4000,
        response_format={"type": "json_object"},
    )
    return response.choices[0].message.content.strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‰´ìŠ¤: ê¸°ì¡´ ë‹¨ì¼ ì—ì´ì „íŠ¸ (ë‰´ìŠ¤ëŠ” ê°€ë²¼ìš°ë¯€ë¡œ 1íšŒë¡œ ì¶©ë¶„)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def select_and_summarize_news(client, news_articles: List[Dict], count: int = 5) -> List[Dict]:
    """ë‰´ìŠ¤ ì¤‘ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê²ƒì„ ì„ ë³„í•˜ê³  3ì¤„ ìš”ì•½"""

    axes_info = load_axes()
    axes_text = "\n".join([f"- Axis {a['id']}: {a['name']} â€” {a['description']}" for a in axes_info])

    news_list = "\n\n".join([
        f"[{i+1}] {n['title']}\nSource: {n['source']}\nURL: {n['url']}\nDescription: {n['description'][:300]}"
        for i, n in enumerate(news_articles[:30])
    ])

    prompt = f"""You are Alchemi, Albert's personal news curator. You deeply understand Albert and curate news specifically for him.

{ALBERT_CONTEXT}

The 5 Axes of interest:
{axes_text}

TASK: Select the {count} most relevant news for Albert. Be highly selective â€” only news that intersects with Albert's specific interests above.

For each selected news, provide:
1. A hashtag keyword in Korean (e.g., #AIì •ì±…, #ì¸ì§€ê³¼í•™, #ëª…ìƒì—°êµ¬, #êµìœ¡í˜ì‹ , #ìƒì‚°ì„±ê³¼í•™)
2. The original title
3. Exactly 3 lines of summary in Korean:
   - Line 1: ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚¬ëŠ”ê°€ (ì‚¬ì‹¤)
   - Line 2: ì™œ ì¤‘ìš”í•œê°€ (ë§¥ë½/ì˜ë¯¸)
   - Line 3: Albertì—ê²Œ ì‹œì‚¬í•˜ëŠ” ì  (ê°œì¸í™”ëœ ì¸ì‚¬ì´íŠ¸)
4. The original URL

IMPORTANT:
- 3ë²ˆì§¸ ì¤„ì€ ë°˜ë“œì‹œ Albertì˜ êµ¬ì²´ì  ìƒí™©(ìˆ˜í–‰, ì½”ì¹­, ê°•ì˜, AI í™œìš© ë“±)ê³¼ ì—°ê²°í•  ê²ƒ
- ë»”í•˜ê±°ë‚˜ genericí•œ ìš”ì•½ì€ í•˜ì§€ ë§ ê²ƒ. ë°€ë„ ë†’ê³  êµ¬ì²´ì ìœ¼ë¡œ.

NEWS ARTICLES:
{news_list}

Respond in JSON format:
{{
  "selected_news": [
    {{
      "hashtag": "#í‚¤ì›Œë“œ",
      "title": "headline",
      "summary_line_1": "ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚¬ëŠ”ê°€",
      "summary_line_2": "ì™œ ì¤‘ìš”í•œê°€",
      "summary_line_3": "Albertì—ê²Œ ì‹œì‚¬í•˜ëŠ” ì ",
      "url": "https://...",
      "source": "source name"
    }}
  ]
}}

Select exactly {count} articles. All summaries MUST be in Korean. Be specific, not generic."""

    try:
        text = _call_groq(client, prompt)
        result = json.loads(text)
        return result.get("selected_news", [])
    except Exception as e:
        print(f"News summarization error: {e}")
        return []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì•„í‹°í´: 3-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _agent_selector(client, articles: List[Dict], count: int, excluded_topics: List[str] = None) -> List[Dict]:
    """Agent 1: Selector â€” ì•„í‹°í´ ì„ ë³„ ì „ë¬¸"""

    axes_info = load_axes()
    axes_text = "\n".join([f"- Axis {a['id']}: {a['name']} â€” {a['description']}" for a in axes_info])

    exclusion_note = ""
    if excluded_topics:
        exclusion_note = f"\n\nEXCLUDED TOPICS (user marked as not interested): {', '.join(excluded_topics)}"

    articles_list = "\n\n".join([
        f"[{i+1}] {a['title']}\nSource: {a['source']} (Tier {a.get('tier', 3)})\nURL: {a['url']}\nPreview: {a.get('content_preview', '')[:500]}"
        for i, a in enumerate(articles[:25])
    ])

    prompt = f"""You are the SELECTOR agent â€” your ONLY job is to pick the best articles for Albert. Do NOT summarize, do NOT analyze. Just select.

{ALBERT_CONTEXT}

The 5 Axes:
{axes_text}

Selection Criteria (in priority order):
1. Paradigm-shifting: Does it introduce a NEW concept, framework, or challenge an existing mental model?
2. Argument over Information: Does it have a clear THESIS and reasoning (not just reporting)?
3. Timeless over Timely: Will this perspective still be valid 10 years from now?
4. Tier priority: Tier 1 (Aeon, Noema, Psyche) > Tier 2 > Tier 3
5. Axis diversity: Try to cover different Axes, not all from the same topic
{exclusion_note}

ARTICLES:
{articles_list}

Select exactly {count} articles. For each, explain in 1 sentence WHY you chose it (what makes it stand out).

Respond in JSON:
{{
  "selected": [
    {{
      "index": 1,
      "title": "article title",
      "source": "source name",
      "url": "https://...",
      "tier": 1,
      "axis_id": 1,
      "axis_name": "Cognition & AI",
      "selection_reason": "Why this article stands out (1 sentence, English)",
      "content_preview": "paste the preview here for the next agent"
    }}
  ]
}}"""

    text = _call_groq(client, prompt)
    result = json.loads(text)
    return result.get("selected", [])


def _agent_analyst(client, selected_articles: List[Dict]) -> List[Dict]:
    """Agent 2: Analyst â€” 3-Point Card ì‘ì„± ì „ë¬¸"""

    articles_detail = "\n\n---\n\n".join([
        f"Article {i+1}: {a['title']}\nSource: {a['source']}\nURL: {a['url']}\nAxis: {a.get('axis_name', '')}\nSelection reason: {a.get('selection_reason', '')}\nPreview: {a.get('content_preview', '')[:800]}"
        for i, a in enumerate(selected_articles)
    ])

    prompt = f"""You are the ANALYST agent â€” your job is to create deep, specific 3-Point Cards. The articles have already been selected for you. Focus ALL your energy on quality analysis.

{ALBERT_CONTEXT}

{ARTICLE_EXAMPLE}

SELECTED ARTICLES:
{articles_detail}

For EACH article, create a 3-Point Card:

CRITICAL RULES:
- ğŸ†• ì™œ ìƒˆë¡œìš´ê°€: What SPECIFIC claim, evidence, or argument is genuinely new? NOT a vague summary. State the concrete novelty in 2 dense sentences.
- ğŸ’ ìƒˆë¡œìš´ ê°œë…: Extract ONE specific concept/framework/term. If the article doesn't name one explicitly, identify the implicit framework and give it a name. The concept name should be in English, the description in Korean.
- ğŸ¯ ì™œ ì½ì–´ì•¼ í•˜ëŠ”ê°€: Connect DIRECTLY to Albert's SPECIFIC situation:
  * His breathing practice (24ì´ˆ-24ì´ˆ ë‹¨ì „í˜¸í¡, ëª©í‘œ íƒœì‹ 2ë¶„)
  * His debate coaching background (8ë…„ ë””ë² ì´íŠ¸í¬ì˜¬)
  * His AI-as-cognitive-extension philosophy
  * His Scholar-Practitioner goal (ê¸°ì—… ê°•ì˜ + ëª…ìƒ ê¸°ë°˜ ìƒì‚°ì„± + ê¸€ì“°ê¸° í”„ë¡œê·¸ë¨)
  * His Microflow writing program
  Pick the MOST relevant connection. Be SPECIFIC, not generic. 2 sentences.

Follow the GOOD EXAMPLE. If your output resembles the BAD EXAMPLE, rewrite it.

Respond in JSON:
{{
  "analyzed_articles": [
    {{
      "title": "article title",
      "source": "source name",
      "url": "https://...",
      "read_time": "12 min",
      "axis_id": 1,
      "axis_name": "Cognition & AI",
      "why_new": "ì™œ ìƒˆë¡œìš´ê°€ (êµ¬ì²´ì , 2ë¬¸ì¥)",
      "new_concept_name": "Concept Name (ì˜ë¬¸)",
      "new_concept_desc": "ê°œë… ì„¤ëª… (1ë¬¸ì¥, í•œêµ­ì–´, ë°€ë„ ë†’ê²Œ)",
      "why_read": "ì™œ ì½ì–´ì•¼ í•˜ëŠ”ê°€ (Albert êµ¬ì²´ì  ìƒí™© ì—°ê²°, 2ë¬¸ì¥)"
    }}
  ]
}}

All Korean must be dense, specific, zero filler words."""

    text = _call_groq(client, prompt)
    result = json.loads(text)
    return result.get("analyzed_articles", [])


def _agent_connector(client, analyzed_articles: List[Dict], starred_articles: List[Dict] = None) -> str:
    """Agent 3: Connector â€” ì•„í‹°í´ ê°„ ì—°ê²°ê³ ë¦¬ ë°œê²¬"""

    articles_summary = "\n".join([
        f"- {a['title']} [{a.get('axis_name', '')}]: {a.get('new_concept_name', '')} â€” {a.get('new_concept_desc', '')}"
        for a in analyzed_articles
    ])

    starred_context = ""
    if starred_articles:
        starred_summary = "\n".join([
            f"- {a.get('title', '')} [{a.get('axis_name', '')}]: {a.get('new_concept_name', '')}"
            for a in starred_articles[:5]
        ])
        starred_context = f"\n\nAlbertê°€ ìµœê·¼ â­ ì¸ìƒì ìœ¼ë¡œ í‘œì‹œí•œ ì•„í‹°í´:\n{starred_summary}"

    prompt = f"""You are the CONNECTOR agent â€” your job is to find the hidden thread that connects today's articles, and optionally connect them to Albert's recent interests.

{ALBERT_CONTEXT}

Today's selected articles:
{articles_summary}
{starred_context}

TASK: Write ONE connecting question or insight in Korean that ties these articles together.

Rules:
- This should be a thought-provoking question or a synthesized insight
- It should connect at least 2 of today's articles
- If starred articles are available, try to connect today's picks with Albert's recent interests
- Keep it to 1-2 sentences, dense and specific
- This will be displayed as "ì´ë²ˆ ë¸Œë¦¬í•‘ì„ ê´€í†µí•˜ëŠ” ì§ˆë¬¸" in the daily briefing

Respond in JSON:
{{
  "connection": "ì˜¤ëŠ˜ì˜ ì•„í‹°í´ì„ ê´€í†µí•˜ëŠ” ì§ˆë¬¸ ë˜ëŠ” ì¸ì‚¬ì´íŠ¸ (1-2ë¬¸ì¥, í•œêµ­ì–´)"
}}"""

    text = _call_groq(client, prompt)
    result = json.loads(text)
    return result.get("connection", "")


def select_and_summarize_articles(
    client, articles: List[Dict], count: int = 3,
    excluded_topics: List[str] = None, starred_articles: List[Dict] = None
) -> List[Dict]:
    """3-ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì•„í‹°í´ íë ˆì´ì…˜"""

    print("  [Agent 1: Selector] Picking best articles...")
    selected = _agent_selector(client, articles, count, excluded_topics)
    print(f"  [Agent 1] Selected {len(selected)} articles")

    if not selected:
        return []

    print("  [Agent 2: Analyst] Creating 3-Point Cards...")
    analyzed = _agent_analyst(client, selected)
    print(f"  [Agent 2] Analyzed {len(analyzed)} articles")

    print("  [Agent 3: Connector] Finding connections...")
    connection = _agent_connector(client, analyzed, starred_articles)
    if connection:
        print(f"  [Agent 3] Connection: {connection[:50]}...")

    # ì—°ê²°ê³ ë¦¬ë¥¼ ì²« ë²ˆì§¸ ì•„í‹°í´ì— ë©”íƒ€ë°ì´í„°ë¡œ ì²¨ë¶€
    if analyzed and connection:
        analyzed[0]["daily_connection"] = connection

    return analyzed
